{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed698ece",
   "metadata": {},
   "source": [
    "## 张量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97997f64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T04:26:30.332514Z",
     "start_time": "2022-09-04T04:26:28.021809Z"
    }
   },
   "source": [
    "### Tensor\n",
    "#### 张量是什么\n",
    "几何代数中定义的张量是基于向量和矩阵的推广，比如我们可以将标量视为零阶张量，矢量可以视为一阶张量，矩阵就是二阶张量。\n",
    "#### 一些常用的张量类型\n",
    "- 3维 = 时间序列\n",
    "- 4维 = 图像\n",
    "- 5维 = 视频  \n",
    "\n",
    "#### 创建张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6538be65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T04:30:26.839340Z",
     "start_time": "2022-09-04T04:30:26.827329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6791, 0.5022, 0.0455],\n",
      "        [0.2783, 0.2004, 0.3984],\n",
      "        [0.5570, 0.6525, 0.8648],\n",
      "        [0.2325, 0.9513, 0.4556]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 随机初始化矩阵（二维张量）\n",
    "a = torch.rand(4,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2af7c9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T04:31:39.838618Z",
     "start_time": "2022-09-04T04:31:39.826347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 全0矩阵构建\n",
    "b = torch.zeros(4,4)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46b5503c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T04:32:45.945967Z",
     "start_time": "2022-09-04T04:32:45.844527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "# 张量的构建 我们可以通过torch.tensor()直接使用数据，构造一个张量：\n",
    "x = torch.tensor([5.5, 3]) \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27d3f2de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T04:35:34.391749Z",
     "start_time": "2022-09-04T04:35:34.368060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-1.4806,  0.6763,  1.7365],\n",
      "        [-2.4384,  0.4306, -0.4925],\n",
      "        [-1.2686, -0.4295, -0.8371],\n",
      "        [-0.6396, -1.6038, -0.1184]])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = a.new_ones(4, 3, dtype=torch.double) \n",
    "# 创建一个新的全1矩阵tensor，返回的tensor默认具有相同的torch.dtype和torch.device\n",
    "# 也可以像之前的写法 x = torch.ones(4, 3, dtype=torch.double)\n",
    "print(x)\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "# 重置数据类型\n",
    "print(x)\n",
    "# 结果会有一样的size\n",
    "# 获取它的维度信息\n",
    "print(x.size())\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c323d8b",
   "metadata": {},
   "source": [
    "### 张量操作\n",
    "#### 张量加法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4264a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T04:45:25.715900Z",
     "start_time": "2022-09-04T04:45:25.687744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "y:  tensor([[0.7403, 0.9667, 0.0351, 0.0470],\n",
      "        [0.6012, 0.7206, 0.0482, 0.6057],\n",
      "        [0.8646, 0.6918, 0.3521, 0.2058],\n",
      "        [0.7555, 0.2405, 0.5929, 0.9158],\n",
      "        [0.6076, 0.5072, 0.1262, 0.3433]])\n",
      "1--->x+y:  tensor([[1.7403, 1.9667, 1.0351, 1.0470],\n",
      "        [1.6012, 1.7206, 1.0482, 1.6057],\n",
      "        [1.8646, 1.6918, 1.3521, 1.2058],\n",
      "        [1.7555, 1.2405, 1.5929, 1.9158],\n",
      "        [1.6076, 1.5072, 1.1262, 1.3433]])\n",
      "2--->x+y:  tensor([[1.7403, 1.9667, 1.0351, 1.0470],\n",
      "        [1.6012, 1.7206, 1.0482, 1.6057],\n",
      "        [1.8646, 1.6918, 1.3521, 1.2058],\n",
      "        [1.7555, 1.2405, 1.5929, 1.9158],\n",
      "        [1.6076, 1.5072, 1.1262, 1.3433]])\n",
      "原值修改！ tensor([[1.7403, 1.9667, 1.0351, 1.0470],\n",
      "        [1.6012, 1.7206, 1.0482, 1.6057],\n",
      "        [1.8646, 1.6918, 1.3521, 1.2058],\n",
      "        [1.7555, 1.2405, 1.5929, 1.9158],\n",
      "        [1.6076, 1.5072, 1.1262, 1.3433]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "x = torch.ones(5,4)\n",
    "y = torch.rand(5,4)\n",
    "print(\"x: \",x)\n",
    "print(\"y: \",y)\n",
    "#方式一 \n",
    "# 注意相加时矩阵size要一致\n",
    "print(\"1--->x+y: \",x+y)\n",
    "#方式2\n",
    "print(\"2--->x+y: \",torch.add(x, y))\n",
    "#方式3 原值修改\n",
    "x.add_(y);\n",
    "print(\"原值修改！\",x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43d6a86",
   "metadata": {},
   "source": [
    "#### 索引操作\n",
    "需要注意的是：索引出来的结果与原数据共享内存，修改一个，另一个会跟着修改。如果不想修改，可以考虑使用copy()等方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7e0ae16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T04:50:37.730093Z",
     "start_time": "2022-09-04T04:50:37.710612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7360, 0.7120, 0.9696])\n",
      "tensor([1.7360, 1.7120, 1.9696])\n",
      "tensor([1.7360, 1.7120, 1.9696])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(4,3)\n",
    "# print(x[:2,:2])\n",
    "\n",
    " # 眼睁睁共享内存机制\n",
    "print(x[0,:])\n",
    "y = x[0,:]\n",
    "y += 1\n",
    "print(y)\n",
    "print(x[0,:]) # 源tensor也被改了了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063fc716",
   "metadata": {},
   "source": [
    "#### 维度变换 \n",
    "张量的维度变换常见的方法有torch.view()和torch.reshape()，下面我们将介绍第一中方法torch.view()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82d18b71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T05:01:36.719134Z",
     "start_time": "2022-09-04T05:01:36.695108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  tensor([[0.4705, 0.7388, 0.0829, 0.1663],\n",
      "        [0.6580, 0.5757, 0.1147, 0.7721],\n",
      "        [0.3177, 0.1814, 0.8073, 0.2266]])\n",
      "torch.Size([3, 4])\n",
      "y:  tensor([0.4705, 0.7388, 0.0829, 0.1663, 0.6580, 0.5757, 0.1147, 0.7721, 0.3177,\n",
      "        0.1814, 0.8073, 0.2266])\n",
      "torch.Size([12])\n",
      "z:  tensor([[0.4705, 0.7388],\n",
      "        [0.0829, 0.1663],\n",
      "        [0.6580, 0.5757],\n",
      "        [0.1147, 0.7721],\n",
      "        [0.3177, 0.1814],\n",
      "        [0.8073, 0.2266]])\n",
      "torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,4)\n",
    "y = x.view(12)\n",
    "z = y.view(-1,2) # -1表示自适应\n",
    "print(\"x: \",x)\n",
    "print(x.size())\n",
    "print(\"y: \",y)\n",
    "print(y.size())\n",
    "print(\"z: \",z)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44e6f26",
   "metadata": {},
   "source": [
    "\n",
    "注: torch.view() 返回的新tensor与源tensor共享内存(其实是同一个tensor)，更改其中的一个，另外一个也会跟着改变。(顾名思义，view()仅仅是改变了对这个张量的观察角度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1af0f290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T05:08:38.716864Z",
     "start_time": "2022-09-04T05:08:38.696861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.4705, 4.7388, 4.0829, 4.1663],\n",
      "        [4.6580, 4.5757, 4.1147, 4.7721],\n",
      "        [4.3177, 4.1814, 4.8073, 4.2266]])\n",
      "tensor([4.4705, 4.7388, 4.0829, 4.1663, 4.6580, 4.5757, 4.1147, 4.7721, 4.3177,\n",
      "        4.1814, 4.8073, 4.2266])\n",
      "tensor([[5.4705, 5.7388, 5.0829, 5.1663],\n",
      "        [5.6580, 5.5757, 5.1147, 5.7721],\n",
      "        [5.3177, 5.1814, 5.8073, 5.2266]])\n",
      "tensor([5.4705, 5.7388, 5.0829, 5.1663, 5.6580, 5.5757, 5.1147, 5.7721, 5.3177,\n",
      "        5.1814, 5.8073, 5.2266])\n"
     ]
    }
   ],
   "source": [
    "print(x) \n",
    "print(y) \n",
    "x += 1\n",
    "# view funtion just change the perspective of tensor\n",
    "# ,if you change the tensor x,the tensor y will also  change \n",
    "print(x) \n",
    "print(y) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aea8ba",
   "metadata": {},
   "source": [
    "### reshape\n",
    "但是很多情况下，我们希望原始张量和变换后的张量互相不影响。为为了使创建的张量和原始张量不共享内存，我们需要使用第二种方法torch.reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dbb2e909",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T05:15:36.101160Z",
     "start_time": "2022-09-04T05:15:36.077011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6156, 0.1800, 0.0839, 0.9338],\n",
      "        [0.8536, 0.8353, 0.9011, 0.3750],\n",
      "        [0.8272, 0.0199, 0.5095, 0.4609],\n",
      "        [0.0567, 0.2472, 0.5745, 0.0522],\n",
      "        [0.3311, 0.5100, 0.3078, 0.2891]])\n",
      "tensor([[0.6156, 0.1800],\n",
      "        [0.0839, 0.9338],\n",
      "        [0.8536, 0.8353],\n",
      "        [0.9011, 0.3750],\n",
      "        [0.8272, 0.0199],\n",
      "        [0.5095, 0.4609],\n",
      "        [0.0567, 0.2472],\n",
      "        [0.5745, 0.0522],\n",
      "        [0.3311, 0.5100],\n",
      "        [0.3078, 0.2891]])\n",
      "tensor([[1.6156, 1.1800, 1.0839, 1.9338],\n",
      "        [1.8536, 1.8353, 1.9011, 1.3750],\n",
      "        [1.8272, 1.0199, 1.5095, 1.4609],\n",
      "        [1.0567, 1.2472, 1.5745, 1.0522],\n",
      "        [1.3311, 1.5100, 1.3078, 1.2891]])\n",
      "tensor([[1.6156, 1.1800],\n",
      "        [1.0839, 1.9338],\n",
      "        [1.8536, 1.8353],\n",
      "        [1.9011, 1.3750],\n",
      "        [1.8272, 1.0199],\n",
      "        [1.5095, 1.4609],\n",
      "        [1.0567, 1.2472],\n",
      "        [1.5745, 1.0522],\n",
      "        [1.3311, 1.5100],\n",
      "        [1.3078, 1.2891]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5,4)\n",
    "# 还是共享了内存 x 随着y改变\n",
    "y = torch.reshape(x,(-1,2))\n",
    "print(x)\n",
    "print(y)\n",
    "y += 1\n",
    "print(x)\n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f17c83",
   "metadata": {},
   "source": [
    "#### clone() ---> view()\n",
    "- 推荐的方法是我们先用 clone() 创造一个张量副本然后再使用 torch.view()进行函数维度变换 。\n",
    "- 使用 clone() 还有一个好处是会被记录在计算图中，即梯度回传到副本时也会传到源 Tensor 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "14dc2dfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T05:18:00.109591Z",
     "start_time": "2022-09-04T05:18:00.093494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([1,2,3,4,5,6,7,8,9])\n",
    "print(x)\n",
    "y = x.clone()\n",
    "print(y)\n",
    "# 维度变化 \n",
    "y = y.view(-1,3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7eabd",
   "metadata": {},
   "source": [
    "#### 取值操作 \n",
    "如果我们有一个元素 tensor ，我们可以使用 .item() 来获得这个 value，而不获得其他性质："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cef38a83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T05:18:34.185327Z",
     "start_time": "2022-09-04T05:18:34.169959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(1) \n",
    "print(type(x)) \n",
    "print(type(x.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfef866",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T05:18:59.517347Z",
     "start_time": "2022-09-04T05:18:59.497980Z"
    }
   },
   "source": [
    "### 广播机制\n",
    "当对两个形状不同的 Tensor 按元素运算时，可能会触发广播(broadcasting)机制：先适当复制元素使这两个 Tensor 形状相同后再按元素运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4a713392",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T05:20:16.465710Z",
     "start_time": "2022-09-04T05:20:16.437700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[2, 3],\n",
      "        [3, 4],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1,3).view(1,2)\n",
    "print(x)\n",
    "y = torch.arange(1, 4).view(3, 1)\n",
    "print(y)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accd45b2",
   "metadata": {},
   "source": [
    "由于x和y分别是1行2列和3行1列的矩阵，如果要计算x+y，那么x中第一行的2个元素被广播 (复制)到了第二行和第三行，⽽y中第⼀列的3个元素被广播(复制)到了第二列。如此，就可以对2个3行2列的矩阵按元素相加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc30b7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "machinelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
