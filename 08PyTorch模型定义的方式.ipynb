{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8564b0e",
   "metadata": {},
   "source": [
    "# PyTorch模型定义的方式\n",
    "模型在深度学习中扮演着重要的角色，好的模型极大地促进了深度学习的发展进步，比如CNN的提出解决了图像、视频处理中的诸多问题，RNN/LSTM模型解决了序列数据处理的问题，GNN在图模型上发挥着重要的作用。当我们在向他人介绍一项深度学习工作的时候，对方可能首先要问的就是使用了哪些模型。因此，在PyTorch进阶操作的第一部分中，我们首先来学习PyTorch模型相关的内容。\n",
    "## 基础知识\n",
    "- Module 类是 torch.nn 模块里提供的一个模型构造类 (nn.Module)，是所有神经⽹网络模块的基类，我们可以继承它来定义我们想要的模型；\n",
    "\n",
    "- PyTorch模型定义应包括两个主要部分：各个部分的初始化（__init__）；数据流向定义（forward）\n",
    "\n",
    "基于nn.Module，我们可以通过Sequential，ModuleList和ModuleDict三种方式定义PyTorch模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6cf736",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T02:16:10.884003Z",
     "start_time": "2022-09-06T02:16:10.881007Z"
    }
   },
   "source": [
    "## sequential\n",
    "当模型的前向计算为简单串联各个层的计算时， Sequential 类可以通过更加简单的方式定义模型。它可以接收一个子模块的有序字典(OrderedDict) 或者一系列子模块作为参数来逐一添加 Module 的实例，⽽模型的前向计算就是将这些实例按添加的顺序逐⼀计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af0b7c84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T02:18:05.064112Z",
     "start_time": "2022-09-06T02:18:02.391045Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_44216/1265018979.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mMySequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMySequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "class MySequential(nn.Module):\n",
    "    from collections import OrderedDict\n",
    "    def __init__(self, *args):\n",
    "        super(MySequential, self).__init__()\n",
    "        if len(args) == 1 and isinstance(args[0], OrderedDict): # 如果传入的是一个OrderedDict\n",
    "            for key, module in args[0].items():\n",
    "                self.add_module(key, module)  \n",
    "                # add_module方法会将module添加进self._modules(一个OrderedDict)\n",
    "        else:  # 传入的是一些Module\n",
    "            for idx, module in enumerate(args):\n",
    "                self.add_module(str(idx), module)\n",
    "    def forward(self, input):\n",
    "        # self._modules返回一个 OrderedDict，保证会按照成员添加时的顺序遍历成\n",
    "        for module in self._modules.values():\n",
    "            input = module(input)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46914354",
   "metadata": {},
   "source": [
    "如何使用Sequential来定义模型。只需要将模型的层按序排列起来即可，根据层名的不同，排列的时候有两种方式：\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead69e32",
   "metadata": {},
   "source": [
    "- 直接排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8278afa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T02:20:21.818913Z",
     "start_time": "2022-09-06T02:20:21.797849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(784,256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,10)\n",
    ")\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d5ed6f",
   "metadata": {},
   "source": [
    "- 使用OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ca5bc7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T02:24:08.880038Z",
     "start_time": "2022-09-06T02:24:08.869028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import torch.nn as nn\n",
    "net2 = nn.Sequential(collections.OrderedDict([\n",
    "    ('fc1',nn.Linear(784,256)),\n",
    "    ('relu1',nn.ReLU()),\n",
    "    ('fc2',nn.Linear(256,10))\n",
    "]))\n",
    "print(net2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bad3dc",
   "metadata": {},
   "source": [
    "使用Sequential定义模型的好处在于简单、易读，同时使用Sequential定义的模型不需要再写forward，因为顺序已经定义好了。但使用Sequential也会使得模型定义丧失灵活性，比如需要在模型中间加入一个外部输入时就不适合用Sequential的方式实现。使用时需根据实际需求加以选择。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ab17a7",
   "metadata": {},
   "source": [
    "## ModuleList\n",
    "对应模块为nn.ModuleList()。\n",
    "\n",
    "ModuleList 接收一个子模块（或层，需属于nn.Module类）的列表作为输入，然后也可以类似List那样进行append和extend操作。同时，子模块或层的权重也会自动添加到网络中来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "886fc8f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T02:29:45.219550Z",
     "start_time": "2022-09-06T02:29:45.198787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=256, out_features=10, bias=True)\n",
      "ModuleList(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = nn.ModuleList([nn.Linear(784,256),nn.ReLU()])\n",
    "net.append(nn.Linear(256,10))# 类似于list\n",
    "print(net[-1])\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4031fae1",
   "metadata": {},
   "source": [
    "ModuleList中元素的先后顺序并不代表其在网络中的真实位置顺序，需要经过forward函数指定各个层的先后顺序后才算完成了模型的定义。具体实现时用for循环即可完成：\n",
    "```python\n",
    "class model(nn.Module):\n",
    "  def __init__(self, ...):\n",
    "    super().__init__()\n",
    "    self.modulelist = ...\n",
    "    ...\n",
    "    \n",
    "  def forward(self, x):\n",
    "    for layer in self.modulelist:\n",
    "      x = layer(x)\n",
    "    return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70dc68d",
   "metadata": {},
   "source": [
    "## ModuleDict\n",
    "ModuleDict和ModuleList的作用类似，只是ModuleDict能够更方便地为神经网络的层添加名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa567c5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T02:35:01.641527Z",
     "start_time": "2022-09-06T02:35:01.618352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=10, bias=True)\n",
      "ModuleDict(\n",
      "  (Linear): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (art): ReLU()\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = nn.ModuleDict({\n",
    "    'Linear':nn.Linear(784,256),\n",
    "    'art':nn.ReLU(),\n",
    "})\n",
    "net['output'] = nn.Linear(256,10)\n",
    "# visit\n",
    "print(net['Linear'])\n",
    "print(net.output)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a30c1e3",
   "metadata": {},
   "source": [
    "## 三种方式比较场景\n",
    "Sequential适用于快速验证结果，因为已经明确了要用哪些层，直接写一下就好了，不需要同时写__init__和forward；\n",
    "\n",
    "ModuleList和ModuleDict在某个完全相同的层需要重复出现多次时，非常方便实现，可以”一行顶多行“；\n",
    "\n",
    "当我们需要之前层的信息的时候，比如 ResNets 中的残差计算，当前层的结果需要和之前层中的结果进行融合，一般使用 ModuleList/ModuleDict 比较方便。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5a2b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c4403f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e2e055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd8ba41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2161181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
