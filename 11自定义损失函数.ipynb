{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3641f3c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-08T13:37:19.549595Z",
     "start_time": "2022-09-08T13:37:19.543935Z"
    }
   },
   "source": [
    "# 自定义损失函数\n",
    "PyTorch在torch.nn模块为我们提供了许多常用的损失函数，比如：MSELoss，L1Loss，BCELoss...... 但是随着深度学习的发展，出现了越来越多的非官方提供的Loss，比如DiceLoss，HuberLoss，SobolevLoss...... 这些Loss Function专门针对一些非通用的模型，PyTorch不能将他们全部添加到库中去，因此这些损失函数的实现则需要我们通过自定义损失函数来实现。另外，在科学研究中，我们往往会提出全新的损失函数来提升模型的表现，这时我们既无法使用PyTorch自带的损失函数，也没有相关的博客供参考，此时自己实现损失函数就显得更为重要了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6f5166",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-08T13:37:41.984706Z",
     "start_time": "2022-09-08T13:37:41.975630Z"
    }
   },
   "source": [
    "## 以函数方式定义\n",
    "事实上，损失函数仅仅是一个函数而已，因此我们可以通过直接以函数定义的方式定义一个自己的函数，如下所示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75084368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-08T13:39:11.331230Z",
     "start_time": "2022-09-08T13:39:11.325220Z"
    }
   },
   "source": [
    "``` python\n",
    "def my_loss(out,target):\n",
    "    loss = torch.mean((output - target) ** 2)\n",
    "    return loss\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4c33b1",
   "metadata": {},
   "source": [
    "\n",
    "## 以类方式定义\n",
    "\n",
    "虽然以函数定义的方式很简单，但是以类方式定义更加常用，在以类方式定义损失函数时，我们如果看每一个损失函数的继承关系我们就可以发现Loss函数部分继承自_loss, 部分继承自_WeightedLoss, 而_WeightedLoss继承自_loss， _loss继承自 nn.Module。我们可以将其当作神经网络的一层来对待，同样地，我们的损失函数类就需要继承自nn.Module类，在下面的例子中我们以DiceLoss为例向大家讲述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "041384c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-08T13:40:25.498332Z",
     "start_time": "2022-09-08T13:40:25.489993Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self,weight=None,size_average=True):\n",
    "        super(DiceLoss,self).__init__()\n",
    "        \n",
    "    def forward(self,inputs,targets,smooth=1):\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        intersection = (inputs * targets).sum()                   \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        return 1 - dice\n",
    "\n",
    "# 使用方法    \n",
    "criterion = DiceLoss()\n",
    "# loss = criterion(input,targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c00c99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-08T13:40:43.828642Z",
     "start_time": "2022-09-08T13:40:43.813639Z"
    }
   },
   "source": [
    "### Tips \n",
    "在自定义损失函数时，涉及到数学运算时，我们最好全程使用PyTorch提供的张量计算接口，这样就不需要我们实现自动求导功能并且我们可以直接调用cuda，使用numpy或者scipy的数学运算时，操作会有些麻烦，大家可以自己下去进行探索。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e1cd06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f006ede0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
